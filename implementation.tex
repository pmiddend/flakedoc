\section{Implementation}

\subsection{Einleitung}

In diesem Kapitel soll auf die Details der Implementierung eingegangen werden. Es
wird zunächst OpenGL eingeführt, was zur Visualisierung eingesetzt wird. Danach
wird OpenCL eingeführt, was für die eigentlichen Berechnungen zuständig ist.

Danach das Verfahren von Stam mittels OpenCL umgesetzt. Als Ausgabe erhält man
ein Schnee-Vektorfeld, was dann weiterverwendet werden kann. Hier wird auch auf
Hindernisse wie Gebäude eingegangen. Dazu gehört das Laden der Hindernisse aus
obj-Dateien sowie die Anzeige mittels OpenGL, sowie die Einspeisung in die
Simulation.

Anschließend wird der fallende Schnee modelliert. Hierzu soll zunächst die
Entstehung von Schnee in der Natur erläutert werden, sowie physikalische
Hindergründe bezüglich fallendem Schnee.

Diese idealen physikalischen Gegebenheiten werden dann in ein einfacheres
Modell transformiert, welches für das Partikelsystem verwendet wird. Zu diesem
Partikelsystem gehört neben der Simulation auch die Visualisierung, für die in
dieser Arbeit Pointsprites verwendet werden.

Im letzten Abschnitt wird schließlich auf die Modellierung der Schneedecke
eingegangen, wobei die Ergebnisse von Manuel Schwarz \cite{Schwarz2012} eine
tragende Rolle spielen. Außerdem werden noch einige weitere
Anwendungsmöglichkeiten der Fluidsimulation wie die Simulation von Rauch
angesprochen.

\subsection{OpenGL}

\begin{itemize}
\item Herkunft, Verwendung, Shader
\end{itemize}

\subsection{OpenCL}

\subsubsection{Einleitung}

\begin{itemize}
\item CFD ist sehr anspruchsvoll was Rechenaufwand angeht
\item Traditionellerweise hat man (für Endanwender) auf CPUs programmiert
\item CPUs haben seit kurzem immerhin mehrere Kerne, sodass OpenMP und MPI Sinn ergeben
\item Die Entwicklung zu mehreren Kernen wurde von der Stromsparüberlegung angetrieben (viele Kerne mit niedrigeren Frequenzen leisten dasselbe, sind aber energieeffizienter)
\item Dadurch außerdem kleinere, spezialisiertere Prozessoren (weniger "wasted transistors")
\item Aber GPUs haben theoretisch wesentlich mehr Rechenpower\cite{Guide2012}
\item Grade CFD ist sauschnell
\item Aber natürlich brauch man Probleme, die gut parallelisierbar sind
\item Definition Concurrency: "A software system is concurrent when it consists of more than one stream of operations that are active and can make progress at one time."
\item Definition Parallelism: "When concurrent software runs on a computer with multiple processing elements so that threads actually run simultaneously, we have parallel computation. Concurrency enabled by hardware is parallelism."
\item In diesem Abschnitt Architektur von OpenCL deutlich machen und klären welche Probleme damit gut lösbar sind.
\end{itemize}

\subsubsection{Architektur}

\begin{itemize}
\item Dezember 2008 released
\item Momentan bei Version 1.2, obwohl das noch wenige implementieren
\item Parallelisierbarkeit erklären: data parallelism und task parallelism
\item Dataparallelism: Idee ist, dass man eine Sammlung von Daten hat, die
nebenläufig upgedatet werden können. Parallelität wird nun grade dadurch
erzeugt, dass man denselben Instructionstream auf jedes Datenelement abfeuert
(nicht etwa für jedes Datenelement 'nen eigenen Thread hat, der sich beliebig
anders verhält als der nächste Thread). Beispiel: Addition zweier Vektoren
(SIMD allgemein).
\item Taskparallelism: Eignet sich vielleicht eher für Traversierung von Graphen
oder so.
\item Platform-Model erklären
    \begin{itemize}
            \item "High level description of the heterogenous system"
            \item Host (gibt nur einen)
            \item Host enthält Devices
            \item Devices enthalten Compute Units
            \item Compute Units enthalten Processing Elements
            \item Host program, was auf Host läuft
            \item Mehrere Kernel laufen auf jeweils einem Device
            \item Execution Model klärt, wie Kernel ausgeführt werden
    \end{itemize}
\item Execution-Model
    \begin{itemize}
            \item "abstract representation of how streams of instructions execute on the heterogenous platform"
            \item Kernelexecution löst die Erstellung eines ganzzahligen "Gitters" aus, jeder Kernel kriegt eine Gitterzelle, die globale ID und wird zum "Work-Item"
            \item Workitems werden in Workgroups zusammengefasst (haben auch ID, bilden eine gröbere Struktur, haben geteilten Speicher, werden auf derselben Computeunit ausgeführt)
            \item Command-Queues, schedulen Kernel, Memorycommands, Synchronisierungskommandos, in-order, out-of-order
            \item Barrieren, Warps
    \end{itemize}
\item Memory-Model
    \begin{itemize}
            \item "the collection of memory regions withing OpenCL and how they interact during an OpenCL computation"
            \item Bufferobjects (eindimensional, beliebige Datentypen), Imageobjects, mehrdimensional usw., Inhalt "versteckt"
            \item Host memory
            \item Global, local, private, constant
            \item Zusammenspiel mit OpenGL
    \end{itemize}
\item Programming model
\begin{itemize}
    \item High level abstractions for algorithm programming
    \item OpenCL-C erläutern
\end{itemize}
\end{itemize}

\subsection{Windsimulation}

\subsubsection{Allgemeines}

Für die Simulation des Winds ist es wichtig, eine möglichst optimale
Datenstruktur zur Speicherung der verwendeten Felder zu verwenden, um
die Speicherzugriffszeiten zu minimieren und die maximale Performance zu
erreichen.

Wie bereits angesprochen bietet OpenCL zur Speicherung die Wahl zwischen Buffern
und Texturen (sofern Texturen auf der Zielplattform unterstützt werden). Beide
Speicher-Arten haben leicht unterschiedliche Anwendungsgebiete. In vielen
Kerneln sind wir daran interessiert, für die \PimiddyQuotes{aktuelle} Zelle den
Wert des Gitters sowie den Wert aller Nachbarn zu bestimmen, wobei der
\PimiddyQuotes{Wert} je nach Feld-Typ entweder Druck, Geschwindigkeit oder etwas
anderes bedeuten kann. Außerdem wird bei der Advektion linear zwischen Voxeln
interpoliert.

Schnelle Zugriffe auf einen Voxel samt seiner Nachbarn sind ein Merkmal von
Texturen, daher würden sie sich für viele Kernel anbieten. Allerdings ist das
Schreiben von 3D-Texturen in OpenCL-1.1 nur mit einer Extension möglich. Als
Hilfsmaßnahme greift man hier üblicherweise zu sogenannten
\PimiddyBegriff{Flat-3D-Texturen} \cite{Harris2003}. Hier werden die einzelnen
\PimiddyQuotes{Scheiben} der dreidimensionalen Struktur nebeneinander in eine
zweidimensionale Textur geschrieben, siehe
\autoref{fig:implementation_flat_3d_texture}. Für die Umrechung zwischen 3D- und
2D-Koordinaten ist etwas Rechenaufwand nötig. 2D-Texturen erlauben außerdem
natürlicherweise nur zweidimensionale Interpolation. Benötigt man
dreidimensionale Interpolation, ist auch hier etwas Mehraufwand zu verrechnen.
Texturen werden optimiert gespeichert, sodass Leseoperationen beschleunigt
werden. Diese optimierte Speicherung führt aber dazu, dass das Schreiben in
Texturen relativ langsam ist. Benchmarks im Zweidimensionalen bestätigten, dass
Buffer tatsächlich schneller sind.

\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{images/flat_3d_texture}
\caption{Veranschaulichung einer Flat-3D-Textur}
\label{fig:implementation_flat_3d_texture}
\end{figure}

Da Buffer eindimensional sind, muss zwischen drei- und eindimensionalen
Koordinaten konvertiert werden. Sei $(x,y,z)$ eine dreidimensionale Koordinate
und $(w,h,d)$ die Dimensionen eines Buffers (er enthält also $w \cdot h \cdot d$
Elemente). Dann erhält man den eindimensionalen Index mittels:

\begin{equation}
i = w \cdot h \cdot z + w \cdot y + x
\end{equation}

Umgekehrt erhält man die $(x,y,z)$-Koordinaten eines Index mittels

\begin{align*}
x &= i \PimiddyModulo w \\
y &= i \PimiddyModulo w \cdot h \\
z &= i / (w \cdot h)  \\
\end{align*}

Im Weiteren wird das Verfahren von Stam in OpenCL umgesetzt. Dabei wird auf
Besonderheiten in der Implementierung eingegangen. Fast alle Kernel greifen
hierbei auf den Buffer zurück, der die Hindernisinformationen enthält. Wie
dieser Buffer gefüllt wird, wird im letzten Abschnitt erläutert.

\subsubsection{Verfahren nach Stam in OpenCL}

Es sollen nun die einzelnen Schritte des Verfahrens in OpenCL-Kernel umgewandelt
werden, wobei an einigen Stellen auf Details verzichtet wird. Der Teil des
Programms, der auf dem Host läuft, soll hier ebenfalls nicht in Gänze erarbeitet
werden. Stattdessen soll deutlich werden, in welcher Reihenfolge die Kernel
aufgerufen werden und welche Daten beim Aufruf gelesen und geschrieben werden.
Aus Einrückungsgründen werden viele Bezeichner abgekürzt, aber immer so, dass aus
der Erläuterung bzw. den Kommentaren noch hervorgeht, was sich dahinter
verbirgt.

Die Simulation benötigt einige persistente Daten Daten, also solche, die
zwischen den Simulationsschritten beibehalten werden und nicht nur temporär für
berechnungen verwendet werden:

\begin{itemize}
\item ein Buffer \PimiddyInlineCode{boundaries} vom Typ
\PimiddyInlineCode{float}, der 1.0 enthält, wenn die zugehörige Gitterzelle ein
Hindernis enthält und 0.0 wenn nicht. Das Befüllen dieses Buffers wird in
Abschnitt xxx beschrieben.
\item ein Buffer \PimiddyInlineCode{velocity} vom Typ
\PimiddyInlineCode{float4}, der das momentane Geschwindigkeitsfeld enthält.
Dieses Feld wird anfangs auf $(0,0,0,0)$ gesetzt. Der Wind wird manuell von
einer Seite in die Simulation gespeist und breitet sich dann aus.
\item Viele der Algorithmen benötigen außerdem das aktuelle Zeitdelta
\PimiddyInlineCode{float dt}, was die Zeit seit dem letzten Simulationsdurchlauf
angibt.
\end{itemize}

\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{images/right_neighborhood}
\caption{Veranschaulichung der Nachbarschaftsstruktur \PimiddyInlineCode{neighbors}}
\label{fig:implementation_right_neighbors}
\end{figure}

Die meisten Kernel werden mit einer dreidimensionalen Arbeitsgröße initialisiert
und müssen auf den aktuellen Voxel, sowie seine Nachbarn zugreifen. Daher bietet
es sich an, den Übergang von einem drei- zu einem eindimensionalen Index in eine
Funktion auszulagern. Diese Funktion kann gleichzeitig testen, ob ein gegebener
Index den Rand des Gitters verlässt, und in dem Fall den nächstbesseren Voxel am
Rand zurückliefern. Diese Funktion \PimiddyInlineCode{i4p} ist im Folgenden
dargestellt:

\PimiddyBeginOpenCLCode
// Bekommt die Gittergroesse s und eine 3D-Position p.
// Liefert einen Index.
uint i4p(uint3 p,uint3 s)
{
    // Komponentenweise in gueltigen
    // Bereich [0,n-1] transformieren
    p = clamp(p,(uint3)(0,0,0),s - (uint3)(1,1,1));
    return s.w * s.h * p.z + s.w * p.y + p.x;
}
\end{lstlisting}

Der erste Schritt im Verfahren von Stam ist die Advektion des Vektorfeldes
\PimiddyInlineCode{velocity}. Der dazugehörige Kernel ist in mehreren Funktionen
und Strukturen aufgeteilt, die nun im einzelnen erklärt werden sollen.

Man benötigt zunächst eine Struktur, um einen Geschwindigkeitswert sowie die direkten
Nachbarn zu speichern (siehe \autoref{fig:implementation_right_neighbors}).

\PimiddyBeginOpenCLCode
typedef struct neighbors
{
    float3 at;
    float3 right,top,back,righttop;
    float3 rightback,topback;
    float3 righttopback;
};
\end{lstlisting}

Diese Struktur wird von einer zugehörigen Funktion zurückgegeben, die eine
beliebige Position im Gitter sowie die Größe des Gitters als Eingabe bekommt:

\PimiddyBeginOpenCLCode
// Parameter genau wie i4p, zusaetzlich
// noch "b"
neighbors neighbors_for_pos(
    global float4 *b,
    uint3 p,
    uint3 s)
{
    neighbors result;
    result.at = b[i4p(p,s)];
    result.right = b[i4p(p+(uint3)(1,0,0),s)];
    result.top = b[i4p(p+(uint3)(0,1,0),s)];
    result.back = b[i4p(p+(uint3)(0,0,1),s)];
    result.righttop = b[i4p(p+(uint3)(0,1,1),s)];
    result.rightback = b[i4p(p+(uint3)(1,0,1),s)];
    result.topback = b[i4p(p+(uint3)(0,1,1),s)];
    result.righttopback = b[i4p(p+(uint3)(1,1,1),s)];
    return result;
}
\end{lstlisting}

Schließlich wollen wir mit Hilfe dieser Nachbarstruktur einen interpolierten
Vektor erzeugen. Hier hilft die Funktion \PimiddyInlineCode{mix}, die linear
zwischen zwei Werten anhand eines dritten Wertes interpoliert:

\PimiddyBeginOpenCLCode
float3 interpolate_neighbors(
    neighbors n,
    // v ist ein Vektor im Intervall [0,1]
    float3 v)
{
    float3
            v1 = mix(
                    mix(n.at ,n.right ,v.x),
                    mix (n.top ,n.righttop ,v.x),
                    v.y),
            v2 = mix(
                    mix(n.back ,n.rightback ,v.x),
                    mix(n.topback ,n. righttopback ,v.x),
                    v.y);

    return mix(v1,v2,v.z);
}
\end{lstlisting}

Der eigentliche Kernel hat schließlich folgende Form:

\PimiddyBeginOpenCLCode
kernel void advection(
    global float *boundary,
    global float3 *input,
    global float3 *output,
    float dt,
    uint3 size)
{
    uint3 position = (int3)(
            get_global_id(0),
            get_global_id(1),
            get_global_id(2));

    uint index = i4p(position);

    if(boundary[index] > 0.5f)
    {
            output[index] = (float3)(0.0f);
            return;
    }

    float4
            v = input[index],
            advected = convert_float3(position) - dt * v,
            fractions = fract(advected_vector);

    neighbors n = neighbors_for_pos(
            input,
            position,
            size);

    output[index] = interpolate_neighbors(
            n,
            fractions);
}
\end{lstlisting}

ür den Projektionsschritt benötigen wir die Divergenz des Vektorfeldes.
Analog zur Advektion definieren wir eine Struktur, um die Von Neumann-
Nachbarschaft eines Gitterpunktes zu speichern:

\PimiddyBeginOpenCLCode
typedef struct vn_neighbors
{
    float4 at;
    float4 left, right;
    float4 top, bottom;
    float4 front, back;
    float boundary_at;
    float boundary_left, boundary_right;
    float boundary_top, boundary_bottom;
    float boundary_front, boundary_back;
};
\end{lstlisting}

Die Struktur enthält zusätzlich noch die zu den Nachbarn gehörigen Hin-
derniswerte, die Bestimmung dieser Werte und die der Vektoren verläuft aber
nach demselben Schema wie bei der Advektion und sei im Folgenden mit
\PimiddyInlineCode{vn\_neighbors\_for\_pos(...)} bezeichnet.
Bei der Bestimmung der Divergenz müssen die Randbedingungen beachtet werden. Ist
einer der Nachbarn von einem Hindernis ausgefüllt, wird statt des Vektors an
dieser Stelle der Nullvektor angenommen. Statt dies jedoch als eine womöglich
aufwändige Bedingung umzusetzen kann stattdessen erneut dieFunktion mix
verwendet werden, wobei als Interpolationsparameter direkt der Hinderniswert
eingesetzt wird. Der zur Divergenz gehörige Kernel sieht so aus:

\PimiddyBeginOpenCLCode
kernel void divergence(
    global float4 *input,
    global float *output,
    global float *boundary,
    uint3 size)
{
    uint4 position = (int3)(
            get_global_id(0),
            get_global_id(1),
            get_global_id(2));

    uint index = i4p(position);

    vn_neighbors n = vn_neighbors_for_pos(
            input,
            position,
            boundary,
            size);

    float3 z = (float3)(0.0f);

    n. left = mix(n.left, z, n.boundary_left);
    n. right = mix(n.right, z, n.boundary_right);
    n.top = mix(n.top, z, n.boundary_top);
    n. bottom = mix(n.bottom, z, n.boundary_bottom);
    n. front = mix(n.front, z, n.boundary_front);
    n. back = mix(n.back, z, n.boundary_back);

    output[index] =
            (n.right - n.left).x +
            (n.bottom - n.top).y +
            (n.front - n.back).z;
}
\end{lstlisting}

\begin{itemize}
\item Dann Jacobiverfahren, hier vor allem Pingpong zwischen Buffern erklären
und wie viele Iterationen man machen muss/kann.
\item Dann Subtraktion des Gradienten
\item Hindernisse, Visualisierung (Laden aus obj-Datei)
\item Hindernisse, Voxelisierung mit binvox (Quelle \cite{Nooruddin2003}, \cite{binvox2012}
\end{itemize}

\subsection{Fallender Schnee}

\subsubsection{Hintergründe}

Schnee ist, genau wie Regen, eine Spezialform von \PimiddyBegriff{Niederschlag}.
Hier soll kurz auf die Entstehung von Niederschlag und die Bildung von
Schneeflocken eingegangen werden\cite{wiki:Luftfeuchtigkeit}.

Überall dort, wo sich eine freie Wasseroberfläche wie z.B. ein See befindet und
die Temparatur einen bestimmten Wert übersteigt, lösen sich Moleküle der
Wasseroberfläche von ihrem Verbund und verdunsten in die Luft. Umgekehrt treffen
verdunstete Wassermoleküle wieder auf die Wasseroberfläche und kondensieren
dort. Die Begriffe \emph{Kondensationsrate} und
\emph{Verdunstungsrate} geben an, wie viel Wasser zu einem Zeitpunkt
verdunstet und wie viel kondensiert.

Stellt man sich eine Wasseroberfläche bei trockener Luft vor, so ist
die Kondensationsrate anfangs 0, da keine Wassermoleküle in der Luft
enthalten sind, die kondensieren können. Die Verdunstungsrate ist
bei einer ausreichend hohen Temperatur allerdings nicht 0. Mit der
Zeit steigt so die Anzahl der Wassermoleküle in der Luft. Dadurch
steigt auch die Kondensationsrate. Die Dichte der Wassermoleküle in
der Luft steigt solange an, bis die Kondensationsrate und die
Verdunstungsrate gleich sind. Die in diesem Gleichgewichtszustand
vorliegende Konzentration von Wassermolekülen in der Luft ist die
\PimiddyBegriff{Sättigungskonzentration} oder \PimiddyBegriff{maximale
Luftfeuchtigkeit}. Sie ist umso höher, je wärmer es ist, siehe
\autoref{fig:implementation_moist_air}.

\begin{figure}[ht]
\centering
\includegraphics[width=10cm]{images/moist_air}
\caption{Der exponentielle Zusammenhang zwischen Temperatur und Sättigungsmenge von Wasserdampf in der Luft. (Artikel Sättigung (Physik) in Wikipedia, das nochmal ggf. mit matlab nachplotten)}
\label{fig:implementation_moist_air}
\end{figure}

Steigt warme Luft mit hoher Wassersättigung vom Boden in die
Atmosphäre auf, kann die Sättigungsmenge in den höheren Luftschichten
über den eigentlich maximalen Wert steigen, es entsteht ein
Ungleichgewicht. Um dieses Ungleichgewicht zu kompensieren, kondensiert
das überschüssige Wasser an sogenannten
\PimiddyBegriff{Kondensationskernen} (beispielsweise Staubpartikeln in
der Luft) und es bilden sich kleine Wassertröpfchen in
Mikrometergröße. Passiert dies großflächig, entstehen Wolken am
Himmel. Verdichten sich die kondensierten Tropfen weiter, werden sie
irgendwann zu schwer und fallen aufgrund der Schwerkraft herunter, es
entsteht \emph{Regen}.

Eine Spezialform der eben beschriebenen Kondensationskernen sind die
\emph{Kristallisationskerne}. Bei Temperaturen unter $0\PimiddyDegree$
C bilden sich an diesen Kernen keine Tropfen sondern \emph{Kristalle}.
Bei starken Minustemperaturen (ab $-40\PimiddyDegree$ C) müssen sie
jedoch nicht vorhanden sein, es bildet sich auch so Kristalle.

Diese Kristalle sind anfangs noch sehr klein, sie wachsen erst während ihres
Falles zu Boden weiter an. Dabei entstehen aufgrund spezieller
Eigenschaften des Wassers charakteristische Formen, siehe
\autoref{fig:implementation_single_snow_crystal}. Durch die Verkettung
mehrerer Kristalle entstehen die Schneeflocken, die man beim
Zubodenfallen beobachten kann. Sie können eine Größe von bis zu 10cm
erreichen\cite{Nau96} und haben ebenfalls vielfältige Formen, die
allerdings keine Symmetrie mehr aufweisen, siehe
\autoref{fig:implementation_real_snowflakes}.

\begin{figure}
    \begin{subfigure}[b]{0.5\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/single_snow_crystal}
            \caption{Ein einzelner \PimiddyQuotes{farn-artiger} Schneekristall\cite{Yanagi2011}.}
            \label{fig:implementation_single_snow_crystal}
    \end{subfigure}
    ~
    \begin{subfigure}[b]{0.5\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/real_snowflakes}
            \caption{Kameraaufnahmen einzelner Schneeflocken mit etwa 1-2cm Durchmesser\cite{Hanesch1966}.}
            \label{fig:implementation_real_snowflakes}
    \end{subfigure}
\end{figure}

\subsubsection{Visualisierung}

Bei der Wahl der Visualisierungsmethode müssen mehrere Faktoren in
Betracht gezogen werden. Die Simulation soll sowohl ruhige
Wetterverhältnisse mit wenigen Schneeflocken als auch Szenen mit
starkem Wind und sehr vielen Schneeflocken behandeln können. Daher ist
einerseits wichtig, dass einzelne Schneeflocken einen gewissen
Detailgrad besitzen, aber die Performance gleichzeitig so wenig wie
möglich beeinträchtigen.

Es sollen mindestens die zwei wichtigsten Eigenschaften einer
Schneeflocke modelliert werden: die Größe und das Aussehen. Beide
Eigenschaften hängen von der Umgebungstemparatur ab. Für den Durchmesser $D$
einer Schneeflocke in Abhängigkeit von der Temperatur $T$ wurde in
\cite{Jun00} folgende Relation aufgestellt:

\begin{equation}
D =
\begin{cases}
0.015 \cdot |T|^{-0.35} & \PimiddyFormelText{ für }T \leq -0.061 \\
0.04 & \PimiddyFormelText{ für }T > -0.061
\end{cases}
\end{equation}

Das Aussehen einer Schneeflocke bestimmt sich primär dadurch, ob
\emph{trockener} oder \emph{feuchter} Schnee vorliegt. Nahe bei
$0\PimiddyDegree$ C ist der Schnee feucht und hat eine hohe
Dichte. Bei kälteren Temperaturen werden die Schneeflocken kleiner und
sehen zarter aus.

Aagaard hat in \cite{Aagaard2004} ein Modell entwickelt, welches die
tatsächliche Form der Schneeflocke abhängig von Dichte und Größe
möglichst genau abbildet. Dazu verwendet er zufällig generierte, weiß
gefüllte Dreiecke, welche die Eiskristalle darstellen sollen. Anhand
des (randomisierten) Durchmessers der Schneeflocke wird eine Anzahl
von \emph{Schichten} ermittelt, in der die Dreiecke dann angeordnet werden,
siehe \autoref{fig:implementation_aagaard_layer_model} und
\autoref{fig:implementation_aagaard_spheres}. Auf diese Art können
vielfältige zufällige Formen generiert und an die aktuellen
Wetterbedingungen angepasst werden. Durch die dreidimensionale
Modellierung kann man den Flocken außerdem eine Rotation geben und sie
von allen Seiten betrachten.

Allerdings ist das Modell sehr laufzeitintensiv. Dies rührt einerseits
daher, dass einzelnen Dreiecke sind transparent sind. Dies führt dazu,
dass weit mehr Fragments erzeugt werden als es Pixel auf dem
Bildschirm gibt. Diesen Effekt nennt man \emph{Overdraw}.

Außerdem werden sehr sehr viele kleine Dreiecke für eine einzelne
Flocke benötigt (Aagaard geht von mindestens 10 aus, maximal über
100). Für 1.000 Flocken erhält man so schon 10.000 Dreiecke. Die
angestrebte Flockenzahl bei heftigem Schneefall liegt aber bei weit
über 1.000 Flocken. Aagaard schlägt daher vor, ein \PimiddyQuotes{Level
of detail}-System einzubauen, bei dem weiter entfernte Flocken durch
simplere Geometrie (z.B. mit weniger Dreiecken) angenähert werden. Er
implementiert dies jedoch selber nicht, da Performance kein
entscheidender Faktor für die Implementierung ist.

\begin{figure}[ht]
    \centering
    \includegraphics{images/aagaard_layer_model}
    \caption{Das Resultat von Aagaards 3D-Modell für die Schneeflocken.}
    \label{fig:implementation_aagaard_layer_model}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics{images/aagaard_spheres}
    \caption{Der schichtweise Aufbau einer Schneeflocke in Aagaards Modell.}
    \label{fig:implementation_aagaard_spheres}
\end{figure}

In dieser Arbeit wird stattdessen eine weit simplere Visualisierung
mit Hilfe von \PimiddyBegriff{Pointsprites} gewählt. Statt mehrerer
Dreiecke repräsentiert nur ein einzelner Punkt eine
Schneeflocke. Punkte in OpenGL sind allerdings keine mathematischen
Punkte, denn sie besitzen eine \emph{Ausdehnung}. Diese ist jedoch
nicht in Weltkoordinaten angegeben, sondern in Pixeln auf dem
Bildschirm. Dies bedeutet auch, dass die Punkte immer zum Betrachter
zeigen, man kann sich nicht um sie herum bewegen, siehe
\autoref{fig:implementation_point_sprite_vs_billboard}. Außerdem muss
-- im Gegensatz zu Dreiecken -- eine Formel für die Größe erdacht
werden, damit weiter entfernte Punkte kleiner werden (für Dreiecke
wird dies mit Hilfe einer perspektivischen Projektionsmatrix
sichergestellt).

\begin{figure}[ht]
    \centering
    \includegraphics{images/point_sprite_vs_billboard}
    \caption{Links ein Schneekristall aus zwei Dreiecken zusammengesetzt, rechts als Pointsprite.}
    \label{fig:implementation_point_sprite_vs_billboard}
\end{figure}

\PimiddyBeginGLSLCode[float=tp,caption={Der zu Pointsprites gehörige Vertexshader},label=lst:implementation_point_sprite_vertex_shader]
uniform mat4 model_view_projection;
uniform vec4 eye_position;

in vec4 position;
in float point_size;

float determine_point_size(float distance_to_camera)
{
   // ...
}

void main()
{
  float distance_to_camera = distance(eye_position,position);
  gl_PointSize = determine_point_size(distance_to_camera);
  gl_Position = model_view_projection * position;
}
\end{lstlisting}

\PimiddyBeginGLSLCode[float=tp,caption={Der zu Pointsprites gehörige Fragmentshader},label=lst:implementation_point_sprite_fragment_shader]
uniform sampler2D snowflake_texture;

out vec4 fragment_color;

void main()
{
  // Einfarbige Punkte (hier weiss)
  // fragment_color = vec4(1.0,1.0,1.0,1.0);
  // Mit Textur:
  fragment_color = texture(snowflake_texture,gl_FragCoord);
}
\end{lstlisting}

Um Pointsprites in OpenGL zu zeichnen, gibt man bei der OpenGL-Funktion
\PimiddyInlineCode{glDrawArrays} den Primitvtyp
\PimiddyInlineCode{GL\_POINTS}
an. \PimiddyListingRef{lst:implementation_point_sprite_vertex_shader}
zeigt den dazugehörigen Vertexshader, der als Input die
Projektionsmatrix, den Augenpunkt, die Größe der Schneeflocke und
deren Position bekommt. Mit Hilfe der Variable
\PimiddyInlineCode{gl\_PointSize}, der man einen
\PimiddyInlineCode{float}-Wert zuweist, kann man die Größe des Punktes
setzen. Die Funktion \PimiddyInlineCode{determine\_point\_size} wird gleich erläutert.
lol

Der Fragmentshader
\PimiddyListingRef{lst:implementation_point_sprite_fragment_shader}
enthält den zweidimensionalen Vektor
\PimiddyInlineCode{gl\_FragCoords} $\in [0,1]^2$. Dieser Vektor gibt
an, wo sich das Fragment innerhalb des aktuellen Punktes
befindet. OpenGL verwaltet also ein eigenes Koordinatensystem
innerhalb des Punktes. Mit Hilfe dessen kann man den Punkten im
Fragmentshader nicht nur eine einheitliche Farbe geben, sondern auch
eine Textur. Die Textur der Punkte wird in der konkreten
Implementierung zufällig aus einer Menge von Texturen ausgewählt, die
zur aktuellen Außentemperatur passen.

Es muss noch die Größe der Pointsprites bestimmt werden. Verwendet
man für seine Szene eine perspektivische Projektion, besteht zwischen
dem Abstand von Objekten und ihrer dargestellten Größe ein
nichtlinearer Zusammenhang. Daher sollte auch für die Größe der
Pointsprites eine ähnliche Proportionalität bestehen. Microsofts
DirectX-Framework verwendet hierfür folgende
Formel\cite{DirectXPointSprites}:

\begin{equation}
S =
S'
\sqrt{
  \frac
  {
    1
  }
  {
    A +
    B \cdot D_e +
    C \cdot D_e^2
  }
}
\end{equation}

In der Formel ist $S'$ die vorgegebene Punktgröße, die Konstanten
$A,B,C$ sind frei wählbar und $D_e$ bezeichnet den Abstand des Punktes
von der Kamera. Die Werte $A=B=C=1$ haben sich als visuell ansprechend
herausgestellt\PimiddyTodo{Werte ergänzen!}.

Mit Hilfe von Pointsprites ist es möglich, auf einem aktuellen System
weit über 100.000 Schneeflocken gleichzeitig anzuzeigen. Es ist jedoch
nicht möglich, diese beliebig rotieren zu lassen, was allerdings
visuell nicht kritisch ist.

\subsubsection{Modellierung}

Nach der visuellen Beschreibung der Schneeflocken soll nun deren
Bewegung erläutert werden. Dazu wird zuerst ein physikalisch
motiviertes Modell eingeführt und danach die Implementierungsdetails
des Partikelsystems erklärt.



\begin{itemize}
\item Grundsätzliche Einteilung
    \begin{itemize}
    \item Kurze Einführung wo Schnee herkommt
    \item Aussehen der Schneeflocken
    \item Simulation der Schneeflocken, erst Physikalisch
    \item Dann, wenn nötige Eigenschaften bekannt sind, Partikelsystem erklären
    \end{itemize}
\item Niederschlag erklären: Luft im Himmel ist mit Wasser gesättigt, das
gesättigte Wasser kondensiert zu Tropfen, Tropfen wachsen bis sie
herunterfallen. Tropfen bilden sich nur, wenn Kondensationskerne (wie Staub) in
der Luft sind, an die das Wasser sich anheften kann.
\item Schneefall: Temparatur muss kleiner 0 Grad sein. Kondensationskerne müssen
eine gewisse Form haben (wird bei $<-40$ Grad unnötig)
\item Schneeflocken haben sehr vielfältige Formen und Größen (Entstehung dieser Formen kurz erklären?)
\item Werden visuell vereinfacht zu Point Sprites
\item Point Sprites Punkte mit Ausdehnung und Textur, zeigen immer zum
Betrachter, Größe selber festlegbar, abhängig von der Kamera, Bild wird atlased
und je nach Flockeneigenschaft (bzw. Temparatur der Umgebung) ausgewählt
\item Physikalische Eigenschaften einer Schneeflocke
\item Kräfte sind gravity, buoyant, lift und drag.
\item Drag ist die Kraft, die die Schneeflocke entlang des Wind treiben lässt
\item Lift lässt die Flocke in Kreisförmigen Bewegungen runterfallen
\item Drag ist definiert durch
\[
F_{drag} = \frac{1}{2} \rho_{air} \vec{U}_{fluid}^2 A C_D
\]
wobei $\rho$ die Dichte der Luft angibt, $U$ die
Geschwindigkeit, $A$ der Durchmesser, $C_D$ der Drag-Koeffizient, der auf die
Form der Schneeflocke ankommt und die Turbulenzen die sie erzeugt.
\item Angenommen die Schneeflocke hat eine bestimmte Masse und fällt mit
terminal velocity nach unten, dann kann man $C_D$ bestimmen (abhängig von $U_{max}, \rho, A, m_{snow}$
\item Das kann man in $F_{drag}$ einsetzen und erhält
\[
F_{drag} = \frac{U_{fluid} m_{snow} g}{U_{max}}
\]
\item Man muss also nur $U_{max}$ schätzen. In \cite{Hanesch1966} wurde das
gemacht (bei -2 bis 0 Grad Celsius). Feststellung: Größe der Schneeflocke hat
kaum Einfluss. Geschwindigkeit ist zwischen $0.5m/s$ und $2m/s$. In
\cite{Canada1999} wurde zudem festgestellt, dass zwischen trockenem Schnee und
nassem Schnee ein Faktor von 2 ergibt, d.h. nasser Schnee hat $1-4m/s$ und
trockener eben $0.5-2$
\item Lift force ist orthogonal zur Dragforce und entsteht durch vortex shedding
hinter der Schneeflocke. Flocke wird zur Seite abgetrieben.
\item Via Weg-Zeit-Gesetz:
\[
s=\frac{1}{2}at^2 + v_0 t + s_0
\]
Berechnen wir die neue Position eine Schneeflocke via:
\[
\vec{p}^{t+\Delta t} = \vec{p}^t + \vec{u} \Delta t + \frac{1}{2} \vec{a} \Delta t^2
\]
D.h. wir speichern eine Geschwindigkeit und Berechnen eine (konstante) Beschleunigung

\textbf{Alternativ}: Schlicht zwei DGL hinschreiben:
\begin{gather}
p^{t + \Delta t} = p^{t} + \Delta t \cdot \vec{u}^{t} \\
\vec{u}^{t+ \Delta t} = \vec{u}^{t} + \Delta t \cdot \vec{a}^{t} \\
\vec{a}^t = \frac{\vec{F}_{ges}}{m_{snow}}
\end{gather}
\item Erste Kraft, Gravitation
\item Zweite Kraft, Auftrieb, wird aber vernachlässigt
\item $F_{lift}$ erzeugt spiralförmige Bewegung, allerdings relativ subtil. Wird angenähert durch:
\[
U_{circ} = C_{vel} \omega (\sin(\omega t),0,\cos(\omega t))
\]
\item Erstmal weglassen
\item Nötige Eigenschaften einer Schneeflocke: Position, Geschwindigkeit (dynamisch), Masse (für Drag), Maximalgeschwindigkeit $U_{max}$.
\item Simulation vom Aufbau her:
    \begin{itemize}
            \item Generiere Zufallswerte für Schneeflockenposition-,
            Geschwindigkeit, Masse, Maximalgeschwindigkeit, Bild
            \item In jedem Frame update Geschwindigkeit und Position
            \item Teste auf Hindernis, falls erfolgreich, generiere neue
            Zufallsposition (oder wenn Schneeflocke außerhalb ist)
            \item Update ggf. die Schneeaktivität.
    \end{itemize}
\item Simulation in Code, Buffersharing mit OpenGL, Shader in OpenG.
\end{itemize}

\subsection{Liegengebliebener Schnee}

\begin{itemize}
\item Marching Cubes, allgemeine Beschreibung
\item Marching Cubes auf der GPU
\item Zusammenhang mit Schneemodell
\item Triplanare bzw. prozedurale Texturierung
\end{itemize}

\subsection{Andere Visualisierungsmöglichkeiten}

\begin{itemize}
\item Rauch
\end{itemize}
